[
    {
        "category": "About",
        "projects": [
            {
                "title": "Biography",
                "description": "George Gausden is a multimedia artist from Montréal. He has worked on a range of projects, from designing a book cover for an author to collaborating with a local artist to digitize and explore new ways to view their art. He has always been interested in creating art, whether it be using traditional mediums or more recently, digital ones. Recently, his main area of focus has been in the field of generative artwork and the emergence of complex behaviours from simple systems. George is in the final stage of completing his Computation Arts degree at Concordia University. Since last summer, he has been collaborating closely with a local Montreal start-up on creating content and designing a website for their brand.",
                "tags": [],
                "links": [["/0001.png"]],
                "text": [[]]
            },
            {
                "title": "Artist Statement",
                "description": "My artistic practice involves combining digital tools with traditional ones. I’m very interested in the mixing of mediums to achieve new results. A lot of my work is focused on aesthetics and there are a lot of repeated curved forms. Part of the reason I include so many curvatures has to do with a desire to bring organic shapes to the digital space. So much of what we do on computers nowadays is far removed from the natural world. I like to draw inspiration from the natural world to develop ideas for future projects. A large chunk of my artistic process involves watching or reading about science and then trying to represent elements of that using code or 3D software. Some projects involve multiple iterations that together form a body of work, while others are meant to be standalone pieces.",
                "tags": [],
                "links": [["/0001.png"]],
                "text": [[]]
            }
        ]
    },
    {
        "category": "Contact",
        "projects": [
            {
                "title": "Email",
                "description": "This is the description for Project 3.",
                "tags": [],
                "links": [["george.philip.gausden@gmail.com"]],
                "text": [[]]
            },
            {
                "title": "CV",
                "description": "This is the description for Project 4.",
                "tags": [],
                "links": [["/CV.pdf"]],
                "text": [[]]
            }
        ]
    },
    {
        "category": "Experiments",
        "projects": [
            {
                "title": "Geometries",
                "description": "Playing around with p5.js and trigonometry to create generative art.",
                "tags": ["p5.js", "Trigonometry", "Generative Art", "Mathematics"],
                "links": [["/geometries1.jpg", "Iteration #1, p5.js, 2023"], ["/geometries2.jpg", "Iteration #2, p5.js, 2023"], ["/geometries3.jpg", "Iteration #3, p5.js, 2023"]],
                "text": [[]]
            },
            {
                "title": "Studio NewKid",
                "description": "I worked with Studio NewKid to develop their brand image. I wanted to use tools that I was already familiar with, such as p5.js, Procreate and Photoshop to create compelling animations verging on the experimental side. During the course of my work at Studio NewKid, I was responsible for some of the photography and graphic design.",
                "tags": ["Marketing", "Photography", "Photoshop", "p5.js", "Illustration"],
                "links": [["/newkid1.webp", "NewKid, 2024"], ["/newkid2.webp", "NewKid, 2024"], ["/newkid3.webp", "NewKid, 2024"], ["/newkid4.webp", "NewKid, 2024"], ["/newkid5.webp", "NewKid, 2024"], ["/newkidgif.gif", "NewKid, 2024"], ["/newkidad.gif","NewKid, 2024"], ["/newkidlogo.gif", "NewKid, 2024"]],
                "text": [[]]
            },
            {
                "title": "3D Modelling",
                "description": "A compilation of 3D experiments & projects",
                "tags": ["3D Modelling", "Animation", "Blender", "Rigging"],
                "links": [["/humanoid.mp4", "Humanoid Alien, Blender, 2023"],["/GeorgeG_Wireman_Model.png","Wireman Model, Blender, 2023"],["/0001.png","Glass Bubbles, Blender, 2023"],["/0002.png","NewKid, Blender, 2023"],["/worms.jpg","Fluff, Blender, 2020"],["/boat.png","Sailing, Blender, 2020"], ["/egg2.png","Egg, Blender, 2024"],["/egg6.png","Egg, Blender, 2024"],["/0001.mp4", "Diorama, 2022"]],
                "text": [[],[]]
            }
        ]
    },
    {
        "category": "Projects",
        "projects": [
            {
                "title": "Performance Flow",
                "description": "A look into machine learning, piano performance & Argon Particle microcontrollers.",
                "tags": ["Machine Learning", "Piano", "Performance", "Argon Particle", "Wekinator"],
                "links": [["/performanceFlow.jpeg", "Argon Particle Microcontrollers, 2024"], ["/process.png", "Diagram of the process, 2024"], ["/mapping.png", "Diagram of the mapping in MaxMSP, 2024"]],
                "text": [["Abstract", "This final project is an experiment in creative interactive machine learning and musical gesture control. Our project aims to transform musical performances by providing new ways for artists to interact with the music. Inspired by previous IML research and similar projects, we tried a few approaches to manipulating musical performances that combined audio processing, machine learning, and sensors. We used Wekinator, MaxMSP, and Particle Argon microcontrollers to control audio effects of a pre-recorded track using hand gestures. The Particle Argon microcontroller records real-time hand data, which is fed into a machine learning model trained with Wekinator, and mapped to control audio effects like pan, filters, pitch modulation, and delay. Throughout the process, we encountered some difficulties and evolved our vision, initially aiming for live performance with real-time audio manipulation and exploring visual integration."], ["Process", "The Particle Argon microcontroller is used to capture hand rotation and position data in real time. This data serves as input for a machine learning model trained using Wekinator. We collected the training data using two MPU6050 sensors, one for each hand, providing three continuous data outputs representing the rotation of each hand. This results in a total of six outputs. These continuous data streams from the microcontrollers are sent to Wekinator as continuous float values via OSC."], ["Mapping", "In Wekinator, these six inputs are mapped using a regression model to four outputs. These outputs are scaled to match the range of the corresponding audio effect input in MaxMSP. Wekinator relays these outputs as OSC messages to MaxMSP, where they trigger audio effects applied to a pre-recorded piano performance. Through a many-to-many mapping approach, the four outputs from Wekinator control four MaxMSPs parameter, manipulating the audio effects. These effects include: Pan: Controlled by rotating wrists left and right. Highpass filter cutoff frequency: Adjusted by rotating wrists outwards. Pitch modulation: Increased or decreased by moving hands up and down. Delay with feedback: Activated by holding palms face up."]]
            },
           
            {
                "title": "Montréal Underground",
                "description": "A 3D modelling project involving CGI and animation.",
                "tags": ["3D Modelling", "Animation", "Blender"],
                "links": [["/vfx2.webp","In situ measurements"],["/vfx.webp", "Final Result, Blender, 2023"],["/vfxvideo.mp4", "Final Result, Blender, 2023"]],
                "text": [["Initial Steps","This project was made using Blender. The goal was to create a 3D model of the Montréal underground metro system. The model was then animated to simulate a train moving through the tunnels."],[ "Challenges","The most challenging part of this project was creating the 3D model of the metro system. The model had to be accurate and detailed, which required a lot of time and effort. Another challenge was animating the train to move through the tunnels. This required a good understanding of keyframe animation and camera movement."], ["Final Result","The final result is a 3D animation of the Montréal underground metro system. The animation shows a train moving through the tunnels, passing by different stations and landmarks. The animation is realistic and detailed, with accurate lighting and textures."]]
            },

            {
                "title": "Flows",
                "description": "A look into particle systems and noise functions using TouchDesigner. Music by Max Richter.",
                "tags": ["TouchDesigner", "Animation", "Noise"],
                "links": [["/movieout.3.mp4", "Flows, TouchDesigner, 2023"]],
                "text": [["Process","This video was made entirely using TouchDesigner. Multiple particle systems and noise functions were used to generate a 3D flowing effect."]]
            },  
            {
                "title": "Asma's Portfolio",
                "description": "A website design project for a local Montréal-based artist. The website was built from the ground up using Next.js. The frontend was designed in Figma and implemented using Tailwind CSS. Xata was used for structured data, and Vercel Blob for media storage.",
                "tags": ["Next.js", "Web Development", "Web Design", "React", "Figma"],
                "links": [["/homepage.jpg", " akhanstudio - Homepage, 2024"],["/portfolio.mp4", "Final Result, Blender, 2023"],["/MacBook Air - 20.jpg", "Final Result, Blender, 2023"]],
                "text": [["Process","I recently collaborated with local Montreal artist Asma Khan to design a website that showcases her portfolio. We began the project in Figma, working closely to craft a clean, modern layout that reflected her artistic style. Figma allowed us to easily iterate on design elements and gather feedback. Once the design was finalized, I developed the components from scratch using Next.js."],[ "Challenges","Working on the website for Asma Khan presented several challenges. One of the main difficulties was translating the detailed Figma design into a fully responsive layout with Next.js. Ensuring that the design looked great across all devices required a lot of trial and error, especially with custom components that needed to scale smoothly. Another challenge was balancing aesthetics with performance; optimizing images and assets to load quickly without sacrificing visual quality took time and careful attention. Additionally, integrating dynamic content, such as Asma's latest projects and exhibitions, posed a learning curve as I had to work with APIs and database management. Despite these challenges, the project pushed me to improve both my design-to-development workflow and my technical skills."],[ "Final Result","The final result was a sleek, visually engaging website that perfectly captured Asma Khan's artistic vision while providing a seamless user experience. The site’s responsive design ensured that it looked great on all devices, and the custom-built components gave it a unique feel that stood out from template-based designs. We were both pleased with how well the site balanced aesthetics and functionality. From a technical perspective, this project was a huge learning experience for me—improving my proficiency with Next.js, mastering responsive design techniques, and understanding the importance of optimization. Overall, the collaboration was a success, and it strengthened my ability to bring creative projects from concept to reality."]]
            },  
            {
                "title": "John & Gen's Wedding",
                "description": "A custom wedding invitation website built using Next.js.",
                "tags": ["Next.js", "Web Development", "Web Design", "React", "Figma"],
                "links": [["/wedding1.jpg", " Wedding invitation landing page"],["/wedding2.jpg", "Wedding invitation countdown and information"]],
                "text": [["Process","I designed and implemented a custom wedding invitation website for my brother and his wife. The design stage was done in Figma and then I coded the website using Next.js."],[ "Link","Here's a link to the full website: https://johnandgen.vercel.app"]]
            }

        ]
    },
    {
        "category": "Web Development",
        "projects": [
            {
                "title": "Chef Aloko",
                "description": "A look into machine learning, piano performance & Argon Particle microcontrollers.",
                "tags": ["Machine Learning", "Piano", "Performance", "Argon Particle"],
                "links": [["/performanceFlow.jpeg", "Argon Particle Microcontrollers, 2024"], ["/process.png", "Diagram of the process, 2024"], ["/mapping.png", "Diagram of the mapping in MaxMSP, 2024"]],
                "text": [["Abstract", "This final project is an experiment in creative interactive machine learning and musical gesture control. Our project aims to transform musical performances by providing new ways for artists to interact with the music. Inspired by previous IML research and similar projects, we tried a few approaches to manipulating musical performances that combined audio processing, machine learning, and sensors. We used Wekinator, MaxMSP, and Particle Argon microcontrollers to control audio effects of a pre-recorded track using hand gestures. The Particle Argon microcontroller records real-time hand data, which is fed into a machine learning model trained with Wekinator, and mapped to control audio effects like pan, filters, pitch modulation, and delay. Throughout the process, we encountered some difficulties and evolved our vision, initially aiming for live performance with real-time audio manipulation and exploring visual integration."], ["Process", "The Particle Argon microcontroller is used to capture hand rotation and position data in real time. This data serves as input for a machine learning model trained using Wekinator. We collected the training data using two MPU6050 sensors, one for each hand, providing three continuous data outputs representing the rotation of each hand. This results in a total of six outputs. These continuous data streams from the microcontrollers are sent to Wekinator as continuous float values via OSC."], ["Mapping", "In Wekinator, these six inputs are mapped using a regression model to four outputs. These outputs are scaled to match the range of the corresponding audio effect input in MaxMSP. Wekinator relays these outputs as OSC messages to MaxMSP, where they trigger audio effects applied to a pre-recorded piano performance. Through a many-to-many mapping approach, the four outputs from Wekinator control four MaxMSPs parameter, manipulating the audio effects. These effects include: Pan: Controlled by rotating wrists left and right. Highpass filter cutoff frequency: Adjusted by rotating wrists outwards. Pitch modulation: Increased or decreased by moving hands up and down. Delay with feedback: Activated by holding palms face up."]]
            },
            {
                "title": "Alien",
                "description": "A 3D modelling project done in the context of a 3D course.",
                "tags": ["3D Modelling", "Animation", "Blender", "Rigging"],
                "links": [["/humanoid.mp4", "Humanoid Alien, Blender, 2023"]],
                "text": [[]]
            },
            {
                "title": "Montréal Underground",
                "description": "A 3D modelling project involving CGI and animation.",
                "tags": ["3D Modelling", "Animation", "Blender"],
                "links": [["/vfx.webp", "Final Result, Blender, 2023"]],
                "text": [[]]
            }
        ]
    }
]
